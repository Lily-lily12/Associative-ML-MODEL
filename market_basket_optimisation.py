# -*- coding: utf-8 -*-
"""Market_Basket_Optimisation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i2Px8tO6XDTdb5s1SbmcYyPmsYx73ZY3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

basket=pd.read_csv('Groceries_dataset.csv')

basket.head()

"""Each row contains single transaction. Hence,we need to group by the items having same date and same member number"""

# Convert the 'Date' column to datetime format for better handling
basket['Date'] = pd.to_datetime(basket['Date'], format='%d-%m-%Y')

# Group by 'Member_number' and 'Date' and aggregate the items
grouped_df = basket.groupby(['Member_number', 'Date']).agg({
    'itemDescription': lambda x: ', '.join(x)
}).reset_index()

print(grouped_df)

df = pd.DataFrame(grouped_df)
df

df.info()

df.shape

# Drop the 'Member_number' and 'Date' columns
df_new = df.drop(columns=['Member_number', 'Date'])

# Display the new DataFrame
print(df_new)

df_new = pd.DataFrame(df_new)
df_new

transactions = []

# Iterate over the range of the DataFrame
for i in range(len(df_new)):
    transactions.append([str(df_new.iloc[i, j]) for j in range(len(df_new.columns))])

print(transactions)

transactions_df=pd.DataFrame(transactions)
transactions_df

!pip install apyori

from apyori import apriori
rules = apriori(transactions = transactions,min_support= 1/len(basket), min_confidence =(100*1/len(basket)) , min_lift = 1, min_length = 2, max_length = 2)

rules=list(rules)

print(rules)

def extract_info(record):
    items = list(record.items)[0]  # Convert frozenset to a list
    support = record.support
    ordered_statistic = record.ordered_statistics[0]  # Assuming there's only one ordered statistic per record
    lhs = list(ordered_statistic.items_base)[0] if ordered_statistic.items_base else None
    rhs = list(ordered_statistic.items_add)[0] if ordered_statistic.items_add else None
    confidence = ordered_statistic.confidence
    lift = ordered_statistic.lift
    return items, support, lhs, rhs, confidence, lift

# Extract information from each record
data = [extract_info(record) for record in rules]

# Create DataFrame
df_N = pd.DataFrame(data, columns=['Items', 'Support', 'LHS', 'RHS', 'Confidence', 'Lift'])

# Display DataFrame
print(df_N)

def extract_info_eclat(itemset, support):
    return itemset, support, None, None, None, None

# Extract information from each frequent itemset
data_eclat = [extract_info_eclat(itemset, support) for itemset, support in zip(['itemsets'], frequent_itemsets_eclat['support'])]

# Create DataFrame for Eclat
df_eclat = pd.DataFrame(data_eclat, columns=['Items', 'Support', 'LHS', 'RHS', 'Confidence', 'Lift'])

# Display DataFrame for Eclat
print(df_eclat)

df_n = pd.DataFrame(df_N)
df_n

df_n.nlargest(n = 10, columns = 'Lift')

"""Using Eclat Algorithm"""